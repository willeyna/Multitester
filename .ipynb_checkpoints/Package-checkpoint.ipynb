{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.special as spec\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import healpy as hp\n",
    "import datetime\n",
    "import sys\n",
    "import glob\n",
    "import os \n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import factorial\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads in parameters for an Energy function brought in from a plot in https://arxiv.org/pdf/1306.2309.pdf\n",
    "params = np.array([[ 7.83668562e+13, -2.29461080e+00],\n",
    "                   [ 4.24024293e+05, -7.25775174e-01],\n",
    "                   [ 5.77647391e+12, -2.27582695e+00],\n",
    "                   [ 9.97827439e+04, -5.66062064e-01]])\n",
    "\n",
    "# MISC UTILITY FUNCTIONS ---\n",
    "\n",
    "def bisection(array,value):\n",
    "    n = len(array)\n",
    "    if (value < array[0]):\n",
    "        return -1\n",
    "    elif (value > array[n-1]):\n",
    "        return n\n",
    "\n",
    "    jl = 0\n",
    "    ju = n-1\n",
    "    while (ju-jl > 1):\n",
    "        jm=(ju+jl)\n",
    "        if (value >= array[jm]):\n",
    "            jl=jm\n",
    "        else:\n",
    "            ju=jm\n",
    "    if (value == array[0]):\n",
    "        return 0\n",
    "    elif (value == array[n-1]):\n",
    "        return n-1\n",
    "    else:\n",
    "        return jl\n",
    "\n",
    "#used in kent dist; spherical dot product\n",
    "def sph_dot(th1,th2,phi1,phi2):\n",
    "    return np.sin(th1)*np.sin(th2)*np.cos(phi1-phi2) + np.cos(th1)*np.cos(th2)\n",
    "\n",
    "\n",
    "def sigmoid(x, c = 3, a = .5):\n",
    "    return 1 / (1 + np.exp(-c * (x - a)))\n",
    "\n",
    "def poisson(u, x):\n",
    "    y = np.exp(-u) * (u**x)/(factorial(x))\n",
    "    return y\n",
    "\n",
    "def gaussian(x,sig,mu):\n",
    "    return np.exp(-np.power(x-mu,2)/(2*np.power(sig,2)))\n",
    "\n",
    "#Takes in the track x,y,error and an angle to measure at and returns a 'gaussian signal term' \n",
    "#Uses Kent distribution/ spehrical gaussian\n",
    "def evPSFd(nue,numu):\n",
    "    kappa = 1./(nue[2])**2\n",
    "    log_dist = np.log(kappa) - np.log(2*np.pi) - kappa + kappa*sph_dot(np.pi/2-nue[1], np.pi/2-numu[1], nue[0], numu[0])\n",
    "    return np.exp(log_dist)\n",
    "\n",
    "#power law function\n",
    "def Efunc(E, a, b):\n",
    "    return a * E**b\n",
    "\n",
    "def pd2sig(p):\n",
    "    return np.sqrt(2)*spec.erfinv(1-p)\n",
    "\n",
    "#p-value with bisecting sort algo.\n",
    "def p_value(x, bkg):\n",
    "    ##bisection sorting \n",
    "    j = bisection(bkg,x)\n",
    "    #all edge cases are handled inside the bisection function \n",
    "    #returns 0 if none are above as it should\n",
    "    return bkg[j+1:].shape[0]/ bkg.shape[0]\n",
    "\n",
    "def sigmoid(x, c = 3, a =.5):\n",
    "    return 1 / (1 + np.exp(-c * (x - a)))\n",
    "\n",
    "#size := max number \n",
    "size = 30\n",
    "CTR = 2\n",
    "\n",
    "TCT, TCC = np.zeros([size+1,size+1]),np.zeros([size+1,size+1])\n",
    "for i in range(1, size):\n",
    "    TCC[:,i] = poisson(i/CTR, np.linspace(0,size,size+1))\n",
    "    TCT[i,:] = poisson(i*CTR, np.linspace(0,size,size+1))\n",
    "TC = (TCT + TCC)\n",
    "for i in range(TC.shape[0]):\n",
    "    for j in range(TC.shape[0]):\n",
    "        TC[i,j] *= (j+i)\n",
    "TC[0,0] = 1e-20\n",
    "TC /= np.sum(TC)\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "# TS LIBRARY\n",
    "\n",
    "#Takes in a lower energy bound, power slope, and # between 0 and 1 and returns an energy\n",
    "#Energy sampler created by math magic\n",
    "def EventE(a,g,cdf):\n",
    "    output = ((-g+1) * cdf/(((-a**(-g+1)) / (-g+1))**-1)) + a**(-g+1)\n",
    "    return output**(1/(-g+1))\n",
    "\n",
    "'''\n",
    "Input: Energy in GeV, topology of neutrino (track = 1, casc = 0) , signal boolean (false = background atmospheric distribution)\n",
    "\n",
    "Output: Percent of events that this kind of event is at the given energy\n",
    "'''\n",
    "#Given sig/bkg and topology, gives the percent of events of this kind at an energy\n",
    "def PercentE(E, t_c, signal = True):\n",
    "    perc = np.zeros_like(E)\n",
    "    E = 10**E\n",
    "\n",
    "    track_b = Efunc(E, *params[0])\n",
    "    track_s = Efunc(E, *params[1])\n",
    "    casc_b = Efunc(E, *params[2])\n",
    "    casc_s = Efunc(E, *params[3])\n",
    "\n",
    "    summed = (track_b + track_s + casc_b + casc_s)\n",
    "\n",
    "    for i in range(t_c.shape[0]):\n",
    "        if t_c[i]:\n",
    "\n",
    "            if signal:\n",
    "                perc[i] = casc_s[i]/ summed[i]\n",
    "            else:\n",
    "                perc[i] = casc_b[i]/ summed[i]\n",
    "            pass\n",
    "\n",
    "        elif not t_c[i]:\n",
    "            if signal:\n",
    "                perc[i] = track_s[i]/ summed[i]\n",
    "            else:\n",
    "                perc[i] = track_b[i]/ summed[i]\n",
    "            pass\n",
    "\n",
    "    return perc\n",
    "\n",
    "\n",
    "# EVENT GENERATION\n",
    "######################################################################\n",
    "\n",
    "def gen(n_Ev, g, topo = 0, inra=None,indec=None):\n",
    "        if(g<=0):\n",
    "            print(\"g (second arg) must be >0, negative sign for spectra is hard-coded\")\n",
    "            return\n",
    "        if topo == 0:\n",
    "            mc = np.load(\"./mcdata/tracks_mc.npy\")\n",
    "        elif topo == 1:\n",
    "            mc = np.load(\"./mcdata/cascade_mc.npy\")\n",
    "        else:\n",
    "            print(\"topo = 0 for tracks, topo = 1 for cascades\")\n",
    "            return\n",
    "        p=mc[\"ow\"]*np.power(np.power(10,mc[\"logE\"]),-g)\n",
    "        p/=np.sum(p)\n",
    "        keySC=np.random.choice( np.arange(len(p)), n_Ev, p=p, replace=False)\n",
    "        evs=np.copy(mc[keySC])\n",
    "        \n",
    "        if(inra!=None and indec!=None):\n",
    "            evs[\"trueRa\"]=inra\n",
    "            evs[\"trueDec\"]=indec\n",
    "\n",
    "            #Note: this method was yanked from a skylab example and might not actually be great\n",
    "            eta = np.random.uniform(0., 2.*np.pi, n_Ev)\n",
    "            sigmags=np.random.normal(scale=evs[\"angErr\"])\n",
    "\n",
    "            evs[\"dec\"] = indec + np.sin(eta) * sigmags\n",
    "            evs[\"ra\"] = inra + np.cos(eta) * sigmags\n",
    "            \n",
    "            changeDecs=evs['dec']> np.pi/2\n",
    "            #over shooting in dec is the same as rotating arounf and subtracting the Dec from pi.\n",
    "            evs['ra'][changeDecs]+=np.pi #rotate the point to the other side\n",
    "            evs['dec'][changeDecs]=np.pi-evs['dec'][changeDecs] #move the Dec accordingly\n",
    "\n",
    "            #undershooting in dec\n",
    "            changeDecs=evs['dec']< -np.pi/2\n",
    "\n",
    "            evs['ra'][changeDecs]+=np.pi #rotate the point to the other side\n",
    "            evs['dec'][changeDecs]=-np.pi-evs['dec'][changeDecs] #move the Dec accordingly\n",
    "\n",
    "            #under or overshooting in ra, a bit easier\n",
    "            evs['ra'][evs['ra']>2*np.pi]-=2*np.pi\n",
    "            evs['ra'][evs['ra']<0]+=2*np.pi\n",
    "        return evs\n",
    "\n",
    "\n",
    "######################################################################\n",
    "\n",
    "# METHODS FOR SIGNAL DETECTION\n",
    "# FOR EACH METHOD TO FUNCTION PROPERLY WITH THE HYPOTHESIS TESTING SCRIPTS THEY MUST RETURN TS AS RETURN VALUE [0]\n",
    "\n",
    "#CLASSIC LLH WITHOUT ENERGY\n",
    "def LLH_detector(tracks,cascades, ra, dec):\n",
    "    evs = np.concatenate([tracks,cascades])\n",
    "    nev = evs.shape[0]\n",
    "    B = 1/(4*np.pi)\n",
    "\n",
    "    S = evPSFd([evs['ra'],evs['dec'],evs['angErr']], [ra,dec])\n",
    "\n",
    "    fun = lambda n, S, B: -np.sum(np.log( ((n/(S.shape[0]))*S) + ((1 - n/(S.shape[0]))*B) ))\n",
    "    opt = minimize(fun, 10, (S,B), bounds = ((0,None),))\n",
    "\n",
    "    n_sig = float(opt.x)\n",
    "    maxllh = -float(opt.fun)\n",
    "    TS = 2*(maxllh - nev*np.log(B))\n",
    "\n",
    "    return TS, n_sig\n",
    "\n",
    "\n",
    "def SMTopoAw(tracks, cascades, ra, dec):\n",
    "    evs = np.concatenate([tracks,cascades])\n",
    "    fS = PercentE(evs['logE'],evs['topo'], True)\n",
    "    fB = PercentE(evs['logE'],evs['topo'], False)\n",
    "    \n",
    "    S = evPSFd([evs['ra'],evs['dec'],evs['angErr']],[ra,dec]) * sigmoid(fS, a = 0.5, c = 2.2)\n",
    "\n",
    "    B = np.zeros_like(S)\n",
    "    B += (1/(4*np.pi)) * fB\n",
    "\n",
    "    fun = lambda n, S, B: -np.sum(np.log( (((n/(S.shape[0]))*S) + ((1 - n/(S.shape[0]))*B))))\n",
    "    opt = minimize(fun, 10, (S,B), bounds = ((0,None),))\n",
    "\n",
    "    injected = float(opt.x)\n",
    "    maxllh = -float(opt.fun)\n",
    "\n",
    "    TS = 2*(maxllh - np.sum(np.log(B)))\n",
    "\n",
    "    return TS, injected\n",
    "\n",
    "def Cascade_Filter(tracks, cascades, ra, dec):\n",
    "    ntrack = tracks.shape[0]\n",
    "    B = 1/(4*np.pi)\n",
    "\n",
    "    S =  evPSFd([tracks['ra'],tracks['dec'],tracks['angErr']],[ra,dec])\n",
    "\n",
    "    fun = lambda n, S, B: -np.sum(np.log( ((n/(S.shape[0]))*S) + ((1 - n/(S.shape[0]))*B) ))\n",
    "    opt = minimize(fun, 10, (S,B), bounds = ((0,None),))\n",
    "    maxllh = -float(opt.fun)\n",
    "    TS = 2*(maxllh - ntrack*np.log(B))\n",
    "    #Applies a cascade prior to the traditional LLH TS for tracks\n",
    "    PRIOR =  np.sum(evPSFd([cascades['ra'],cascades['dec'],cascades['angErr']],[ra,dec]))\n",
    "\n",
    "    TS *= PRIOR\n",
    "\n",
    "    return TS, PRIOR\n",
    "\n",
    "# DIFFERENT VARIENT ON CLASSIC LLH (DESCRIBED IN AN OLD POWERPOINT IN MSU ICECUBE DRIVE)\n",
    "def RLLH(tracks,cascades,ra,dec):\n",
    "    evs = np.concatenate([tracks,cascades])\n",
    "\n",
    "    S = evPSFd([evs['ra'],evs['dec'],evs['angErr']], [ra,dec])\n",
    "    B = 1/(4*np.pi)\n",
    "\n",
    "    alpha = S > B\n",
    "    ns = np.sum(alpha)\n",
    "    S = S[alpha]\n",
    "\n",
    "    TS = 2*np.sum(np.log(S/B))\n",
    "\n",
    "    return TS, ns\n",
    "\n",
    "# ROB'S MULTIMAP METHOD WITHOUT Energy\n",
    "def MM(tracks, cascades, ra = 45, dec = 60):\n",
    "    St =  evPSFd([tracks['ra'],tracks['dec'],tracks['angErr']], [ra,dec])\n",
    "    Sc = evPSFd([cascades['ra'],cascades['dec'],cascades['angErr']], [ra,dec])\n",
    "    TS = (np.sum(St)/tracks.shape[0]) * (np.sum(Sc) / cascades.shape[0])\n",
    "    return TSs\n",
    "\n",
    "# TOPOLOGY RATIO PRIOR APPLIED\n",
    "# THIS VERSION DOES NOT USE knn FOR  SIGNAL COUNT; USES LLH MAXIMIZER\n",
    "def TCP(tracks, cascades, ra = 45, dec = 60):\n",
    "    nsc = int(round(LLH_detector0(cascades, ra, dec)[1]))\n",
    "    nst = int(round(LLH_detector0(tracks, ra, dec)[1]))\n",
    "    prior = TC[nst,nsc]\n",
    "\n",
    "    TS0 = LLH_detector(tracks, cascades, ra, dec)[0]\n",
    "    TS = TS0 * prior\n",
    "    return TS, prior, [nst,nsc], TS0\n",
    "\n",
    "# runs LLH_detector 3 times per function run. Time should go as 3t?\n",
    "def TruePrior(tracks, cascades, ra, dec, TC=TC):\n",
    "    evs = np.concatenate([tracks,cascades])\n",
    "    nev = evs.shape[0]\n",
    "\n",
    "    # spatial bkg and signal terms \n",
    "    B = 1/(4*np.pi)\n",
    "    S = evPSFd([evs['ra'],evs['dec'],evs['angErr']], [ra,dec])\n",
    "\n",
    "    # LLH calculations/maximizations \n",
    "    fun = lambda n, S, B: -np.sum(np.log( ((n/(S.shape[0]))*S) + ((1 - n/(S.shape[0]))*B) ))\n",
    "    opt = minimize(fun, 10, (S,B), bounds = ((0,None),))\n",
    "    n_sig = float(opt.x)\n",
    "    maxllh = -float(opt.fun)\n",
    "\n",
    "    # null likelihood\n",
    "    L0 = nev*np.log(B).astype('float128')\n",
    "\n",
    "    # prior calculation\n",
    "    nst = LLH_detector0(tracks, ra, dec)[1]\n",
    "    nsc = LLH_detector0(cascades, ra, dec)[1]\n",
    "    prior = TC[nst,nsc].astype('float128')\n",
    "\n",
    "    offset = np.log(np.exp(maxllh) + np.exp(L0)*((1/prior) - 1))\n",
    "\n",
    "    return np.exp(maxllh - offset),\n",
    "\n",
    "def LLH_detector0(evs, ra, dec):\n",
    "    nev = evs.shape[0]\n",
    "    ns = np.arange(0,nev)\n",
    "    B = 1/(4*np.pi)\n",
    "\n",
    "    S = evPSFd([evs['ra'],evs['dec'],evs['angErr']], [ra,dec])\n",
    "    nfit, sfit = np.meshgrid(ns, S)\n",
    "\n",
    "    lsky = np.log( (nfit/(nev))*sfit + (1 - nfit/(nev))*B )\n",
    "    injected = (np.argmax(np.sum(lsky,axis=0)))\n",
    "    maxllh = np.max(np.sum(lsky,axis=0))\n",
    "\n",
    "    TS = 2*(maxllh - nev*np.log(B))\n",
    "\n",
    "    return maxllh, injected, TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_tester():\n",
    "    \n",
    "    def __init__(self, methods, tracks, cascades):\n",
    "        \n",
    "        #list of method names exactly as they are written in the package (ex \"LLH_detector\")\n",
    "        self.Methods = methods\n",
    "        \n",
    "        #number of mc background tracks and cascades to create background TS for and test with\n",
    "        #will be consistent for everything this object is used for\n",
    "        self.track_count = tracks\n",
    "        self.cascade_count = cascades\n",
    "        #status on whether the program has been run for this object\n",
    "        self.ran = False\n",
    "        return\n",
    "    \n",
    "    def __repr__(self):\n",
    "        if self.ran:\n",
    "            desc = f'''Multi-tester object using the following methods: {self.Methods}\\nBackground tracks: {self.track_count} Background Cascades: {self.cascade_count}\\nRan with filename: {self.name} testing an injection of {self.ninj_t} tracks and {self.ninj_c} cascades\n",
    "            '''\n",
    "        else:\n",
    "            desc = f'''Multi-tester object using the following methods: {self.Methods}\\nBackground tracks: {self.track_count} Background Cascades: {self.cascade_count}\n",
    "            '''\n",
    "        return desc\n",
    "    \n",
    "    '''\n",
    "    Inputs: # of trials, # of files to split into, runtime for each file\n",
    "            injection counts, injection angle, \n",
    "    Writes sb files for each event, repackage sb, and the sdag to control them-- runs these\n",
    "    Returns: Background filename, Significances filename  \n",
    "    \n",
    "    Both the background TS distribution creation and an array of significances tested against the background\n",
    "    Choose so many things in this function \n",
    "    '''\n",
    "    def run(self, bkg_trials, filecount, runtime, mem = '50G', signal_trials = 0, ninj_tracks = 0, ninj_cascades = 0, inj_ra = 0, inj_dec = 0, outpath = './results/', clean = True):\n",
    "        \n",
    "        if type(runtime) != type(''):\n",
    "            raise ValueError('Input runtime as a string of the form hr:min:seconds (ex 5:00:00 for 5 hours)')\n",
    "            return\n",
    "        \n",
    "        if(ninj_tracks+ninj_cascades > 0 and signal_trials == 0):\n",
    "            raise ValueError(f'{ninj_tracks} track events and {ninj_cascades} cascade events injected, but no signal trial count specified.')\n",
    "            return\n",
    "        if(signal_trials > 0 and ninj_tracks+ninj_cascades == 0):\n",
    "            raise ValueError(f'Signal trial count specified, but no events injected')\n",
    "            return\n",
    "        \n",
    "        #all files will be created in ./WIP and so add ../ to make outpath relative to the main directory\n",
    "        self.outpath = '../' + outpath\n",
    "        \n",
    "        self.timetag = (\"\".join(filter(str.isdigit, str(datetime.datetime.now()))))\n",
    "        self.pkl = 'multitester_' + self.timetag + '.pkl'\n",
    "        \n",
    "        #number of events per job\n",
    "        self.nper= bkg_trials//filecount\n",
    "        #write bkg sbatchs\n",
    "        filnam=\"multitester_\" + self.timetag\n",
    "        self.name = filnam\n",
    "        for i in range(filecount):\n",
    "            filstr=filnam+\"_\"+str(i)+\".sb\"\n",
    "            f = open('./templates/bkgjob.txt', 'r')\n",
    "            filetxt = f.read().format(time = runtime, mem = mem, tasknm = 'multitester_' + self.timetag, obj = self.pkl)\n",
    "            f.close()\n",
    "            f = open('./working/' +filstr, 'w+')\n",
    "            f.write(filetxt)\n",
    "            f.close()\n",
    "            \n",
    "        #write repackage sbatch\n",
    "        f = open('./templates/repack.txt', 'r')\n",
    "        filetxt = f.read().format(tasknm = 'multitester_' + self.timetag + '_REPACK', obj = self.pkl)\n",
    "        f.close()\n",
    "        f = open('./working/repack_' + filnam + '.sb', 'w+')\n",
    "        f.write(filetxt)\n",
    "        f.close()\n",
    "        \n",
    "        #write clean script sbatch\n",
    "        f = open('./templates/clean.txt', 'r')\n",
    "        filetxt = f.read().format(tasknm = 'multitester_' + self.timetag + '_CLEAN', obj = self.pkl)\n",
    "        f.close()\n",
    "        f = open('./working/clean_' + filnam + '.sb', 'w+')\n",
    "        f.write(filetxt)\n",
    "        f.close()\n",
    "        \n",
    "        \n",
    "        #case where width based significance calculation is triggered-- else can be done explicitly in a script after backround distribution is created\n",
    "        if signal_trials:\n",
    "            #a few checks\n",
    "            if min([bkg_trials, filecount, signal_trials, ninj_tracks, ninj_cascades]) < 0:\n",
    "                raise ValueError('Some inputted value is negative')\n",
    "                return \n",
    "            if ninj_tracks == 0 and ninj_cascades == 0:\n",
    "                raise ValueError('Please input a number of tracks and cascades to inject for signal trials')\n",
    "                return\n",
    "            \n",
    "            self.ninj_t = ninj_tracks\n",
    "            self.ninj_c = ninj_cascades\n",
    "            self.inj_ra = inj_ra\n",
    "            self.inj_dec = inj_dec\n",
    "            \n",
    "            #write signal sbatch \n",
    "            f = open('./templates/signaljob.txt', 'r')\n",
    "            filetxt = f.read().format(time = runtime, mem = mem, tasknm = 'multitester_signal_' + self.timetag, obj = self.pkl)\n",
    "            f.close()\n",
    "            f = open('./working/signal_' + filnam + '.sb', 'w+')\n",
    "            f.write(filetxt)\n",
    "            f.close()\n",
    "            \n",
    "            #write signal summation sbatch\n",
    "            f = open('./templates/signal_summation.txt', 'r')\n",
    "            filetxt = f.read().format(time = runtime, mem = mem, tasknm = 'multitester_' + self.timetag + '_SIGNAL', obj = self.pkl)\n",
    "            f.close()\n",
    "            f = open('./working/sigsum_' + filnam + '.sb', 'w+')\n",
    "            f.write(filetxt)\n",
    "            f.close()\n",
    "            \n",
    "        #WRITE SDAG-----------\n",
    "        #str of jobs and their sdag names\n",
    "        joblist = ''\n",
    "        #str of each bkgTS dist creating job for calling as parents/children\n",
    "        jstr = ''\n",
    "\n",
    "        for i in range(filecount):\n",
    "            joblist += f'JOB J{i} ./working/{filnam}_{i}.sb\\n'\n",
    "            jstr += f'J{i} '\n",
    "        joblist += f'JOB RP ./working/{filnam}_rp.sb\\n'\n",
    "        joblist += f'JOB CLEAN ./working/{filnam}_clean.sb\\n'\n",
    "            \n",
    "        if signal_trials:\n",
    "            joblist += f'JOB S ./working/signal_{filnam}.sb\\n'\n",
    "            joblist += f'JOB SRP ./working/{filnam}_srp.sb\\n'\n",
    "            \n",
    "            contents = joblist + '\\nPARENT S CHILD ' + jstr + '\\nPARENT ' + jstr + 'CHILD R SRP'\n",
    "            if clean:\n",
    "                contents += '\\nPARENT R SRP CHILD CLEAN'\n",
    "        else: \n",
    "            contents = joblist + '\\nPARENT ' + jstr + 'CHILD R' \n",
    "            if clean:\n",
    "                contents += '\\nPARENT R CHILD CLEAN'\n",
    "\n",
    "        fout=open(f'./working/{filnam}.sdag',\"w\")\n",
    "        fout.write(contents)\n",
    "        fout.close()\n",
    "        \n",
    "        bkg_filename = 'multitester_' + self.timetag + \"_BKG.npz\"\n",
    "        signal_filename = 'multitester_' + self.timetag + \"_SIGMA.npz\"\n",
    "        \n",
    "        #start the program \n",
    "        #os.system(f'python2 sdag.py ./working/{filnam}.sdag')\n",
    "        \n",
    "        self.ran = True\n",
    "        self.bkg = bkg_filename\n",
    "        self.signal = signal_filename\n",
    "        \n",
    "        #saves this object in a pkl file to be read in by other scripts\n",
    "        dbfile = open('./Testers/multitester_' + self.timetag + '.pkl', 'wb+')\n",
    "        pickle.dump(self, dbfile)                     \n",
    "        dbfile.close()\n",
    "            \n",
    "        return\n",
    "    \n",
    "\n",
    "    '''\n",
    "    Inputs: None \n",
    "    Returns: BKG dist numpy array, SIGNAL dist numpy array\n",
    "    '''\n",
    "    def load_TS(self):\n",
    "        try:\n",
    "            bkg_dist = np.load(\"./data/\"+self.bkg)\n",
    "            signal_dist = np.load(\"./data/\"+self.signal)\n",
    "            print(\"TS distributions successfully loaded in\")\n",
    "            return bkg_dist, signal_dist\n",
    "        except: \n",
    "            raise EnvironmentError('Is the background file missing/ created yet?')\n",
    "            \n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs: Injection information, and point on the sky\n",
    "    Creates a MC sky according to specs in object and evaluates each method at a given point in the sky\n",
    "    Returns: Array of TS for each method\n",
    "    \"\"\"\n",
    "    def test_methods(self, ra, dec, ninj_t = 0, ninj_c = 0, inj_ra = 0, inj_dec = 0): \n",
    "        tracks = np.concatenate([gen(ninj_t, 2, 0, inra = inj_ra, indec = inj_dec),gen(self.track_count, 3.7, 0)])\n",
    "        cascades = np.concatenate([gen(ninj_c, 2, 1, inra = inj_ra, indec = inj_dec),gen(self.cascade_count, 3.7, 1)])\n",
    "        output = np.zeros(len(self.Methods))\n",
    "        for i,method in enumerate(self.Methods):\n",
    "            output[i] = eval(method + '(tracks, cascades, ra, dec)')[0]\n",
    "        return output\n",
    "    \n",
    "    def create_sky(self, ninj_t = 0, ninj_c = 0, inj_ra = 0, inj_dec = 0, resolution = 8):\n",
    "        #resolution of healpy grid\n",
    "        NSIDE = 2**8\n",
    "        NPIX = hp.nside2npix(NSIDE)\n",
    "\n",
    "        #angle array of every point on the sky\n",
    "        m = np.arange(NPIX)\n",
    "        theta, phi = np.deg2rad(hp.pix2ang(nside=NSIDE, ipix=m, lonlat = True))\n",
    "        self.sky = np.zeros([NPIX, len(self.Methods)])\n",
    "        \n",
    "        tracks = np.concatenate([gen(ninj_t, 2, 0, inra = inj_ra, indec = inj_dec),gen(self.track_count, 3.7, 0)])\n",
    "        cascades = np.concatenate([gen(ninj_c, 2, 1, inra = inj_ra, indec = inj_dec),gen(self.cascade_count, 3.7, 1)])\n",
    "        \n",
    "        for i in tqdm(range((NPIX))):\n",
    "            for k, method in enumerate(self.Methods):\n",
    "                self.sky[i][k] = eval(method + '(tracks, cascades, theta[i], phi[i])')[0]\n",
    "                \n",
    "        return self.sky \n",
    "    \n",
    "    def show_sky(self, show = False):\n",
    "        for i in range(self.sky.shape[1]):\n",
    "            hp.mollview(self.sky[:,i])\n",
    "            if show:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.savefig('./plots/' + self.name+ self.Methods[i])\n",
    "        return\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs: Location or TS (bool mode switch)\n",
    "    Compares TS against a loaded background the calculate the significance level \n",
    "    Returns: sigma\n",
    "    \"\"\"\n",
    "    def calculate_sigma(self, TS, bkg):\n",
    "        sig = pd2sig(p_value(TS,bkg))\n",
    "        #Placeholder calculation-- figure out a more professional way to deal with overflow\n",
    "        if sig == 0:\n",
    "            sig=np.infty\n",
    "        return sig\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs: Test specifications\n",
    "    Runs background trials on the HPCC (not yet in a job) for the method and prints out \n",
    "    all the useful benchmarking info one would need to calculate the stuff for background files \n",
    "    Returns: Total time to run N trials, Average time per trial, Array of each time per trial\n",
    "    \"\"\"\n",
    "    def benchmarking(self, N):\n",
    "        times = np.zeros(N)\n",
    "        for i in tqdm(range(N)):\n",
    "            t1 = datetime.datetime.now()\n",
    "            self.test_methods(0,0)\n",
    "            t2 = datetime.datetime.now()\n",
    "            times[i] = (t2-t1).total_seconds()\n",
    "        return np.sum(times), np.mean(times), times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = multi_tester(['LLH_detector', 'RLLH'], tracks = 200, cascades = 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.run(1000000, 20, '4:00:00', signal_trials =1000, ninj_tracks = 2, ninj_cascades = 2, inj_ra = np.pi/4, inj_dec = np.pi/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 786432/786432 [06:37<00:00, 1977.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-2.27373675e-13,  1.95018267e+01],\n",
       "       [-2.27373675e-13,  1.94964797e+01],\n",
       "       [-2.27373675e-13,  1.94605605e+01],\n",
       "       ...,\n",
       "       [-2.27373675e-13,  9.16525314e+00],\n",
       "       [-2.27373675e-13,  9.07457512e+00],\n",
       "       [-2.27373675e-13,  9.05854495e+00]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.create_sky(ninj_t = 2, ninj_c = 2, inj_ra = np.pi/4, inj_dec = np.pi/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.benchmarking(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
